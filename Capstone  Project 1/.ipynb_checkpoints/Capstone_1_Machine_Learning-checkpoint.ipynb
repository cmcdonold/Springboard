{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset I am working with is pre-split into two files, one that contains the training dataset and one that contains the independent dataset. Up to this point, I have been working exclusively with the training dataset for exploratory data analysis and statistical inference. However, rather than using only the training set to train various classifiers, I have instead decided to combine the training and independent datasets into one dataframe so that I can then create my own train/test splits on the data forhyperparameter tuning, cross-validation and assessment. The following table shows the first five rows of the resulting combined dataframe of the raw gene expression data, with the individual genes as the columns and the patient samples as the rows. Overall, there are 7129 genes and 72 samples; however, I will only be working with a small subset of the genes for the subsequent analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "sns.set()                       # sets default plot style\n",
    "plt.rc('font', size=14)         # controls default text sizes\n",
    "plt.rc('axes', titlesize=18)    # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=16)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=14)   # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=14)   # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=18)   # fontsize of the legend labels\n",
    "\n",
    "# Read the training dataset into a pandas DataFrame from the 'data_set_ALL_AML_train.csv' file\n",
    "file = 'data_set_ALL_AML_train.csv'\n",
    "data_train = pd.read_csv(file, index_col=1)\n",
    "key = pd.read_csv('actual.csv', index_col=0)\n",
    "\n",
    "# Drop the 'call' and 'Gene Description' columns as they are not relevant\n",
    "drop_list = ['call'] + ['call.' + str(x) for x in range(1,38)]\n",
    "data_train = data_train.drop(columns=drop_list)\n",
    "data_train = data_train.drop(['Gene Description'], axis=1)\n",
    "\n",
    "# Map the gene expression columns to integers and sort the index so that patient samples are in order from 1 to 37\n",
    "data_train.columns = data_train.columns.astype(int)\n",
    "data_train.sort_index(axis=1, inplace=True)\n",
    "\n",
    "# Transpose rows and columns so that each column is a different gene\n",
    "gene_data_train = data_train.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Gene Accession Number</th>\n",
       "      <th>AFFX-BioB-5_at</th>\n",
       "      <th>AFFX-BioB-M_at</th>\n",
       "      <th>AFFX-BioB-3_at</th>\n",
       "      <th>AFFX-BioC-5_at</th>\n",
       "      <th>AFFX-BioC-3_at</th>\n",
       "      <th>AFFX-BioDn-5_at</th>\n",
       "      <th>AFFX-BioDn-3_at</th>\n",
       "      <th>AFFX-CreX-5_at</th>\n",
       "      <th>AFFX-CreX-3_at</th>\n",
       "      <th>AFFX-BioB-5_st</th>\n",
       "      <th>AFFX-BioB-M_st</th>\n",
       "      <th>AFFX-BioB-3_st</th>\n",
       "      <th>AFFX-BioC-5_st</th>\n",
       "      <th>AFFX-BioC-3_st</th>\n",
       "      <th>AFFX-BioDn-5_st</th>\n",
       "      <th>AFFX-BioDn-3_st</th>\n",
       "      <th>AFFX-CreX-5_st</th>\n",
       "      <th>AFFX-CreX-3_st</th>\n",
       "      <th>hum_alu_at</th>\n",
       "      <th>AFFX-DapX-5_at</th>\n",
       "      <th>AFFX-DapX-M_at</th>\n",
       "      <th>AFFX-DapX-3_at</th>\n",
       "      <th>AFFX-LysX-5_at</th>\n",
       "      <th>AFFX-LysX-M_at</th>\n",
       "      <th>AFFX-LysX-3_at</th>\n",
       "      <th>...</th>\n",
       "      <th>Z34822_f_at</th>\n",
       "      <th>U87593_f_at</th>\n",
       "      <th>U88902_cds1_f_at</th>\n",
       "      <th>AC002076_cds2_at</th>\n",
       "      <th>D64015_at</th>\n",
       "      <th>HG2510-HT2606_at</th>\n",
       "      <th>L10717_at</th>\n",
       "      <th>L34355_at</th>\n",
       "      <th>L78833_cds4_at</th>\n",
       "      <th>M13981_at</th>\n",
       "      <th>M21064_at</th>\n",
       "      <th>M93143_at</th>\n",
       "      <th>S78825_at</th>\n",
       "      <th>U11863_at</th>\n",
       "      <th>U29175_at</th>\n",
       "      <th>U48730_at</th>\n",
       "      <th>U58516_at</th>\n",
       "      <th>U73738_at</th>\n",
       "      <th>X06956_at</th>\n",
       "      <th>X16699_at</th>\n",
       "      <th>X83863_at</th>\n",
       "      <th>Z17240_at</th>\n",
       "      <th>L49218_f_at</th>\n",
       "      <th>M71243_f_at</th>\n",
       "      <th>Z78285_f_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-214.0</td>\n",
       "      <td>-153.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-295.0</td>\n",
       "      <td>-558.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>-41.0</td>\n",
       "      <td>-831.0</td>\n",
       "      <td>-653.0</td>\n",
       "      <td>-462.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>-118.0</td>\n",
       "      <td>-565.0</td>\n",
       "      <td>15091.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>-231.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-107.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-325.0</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>-306.0</td>\n",
       "      <td>-1827.0</td>\n",
       "      <td>1582.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>-125.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>793.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>-37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-139.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>-264.0</td>\n",
       "      <td>-400.0</td>\n",
       "      <td>-330.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-743.0</td>\n",
       "      <td>-239.0</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>-141.0</td>\n",
       "      <td>-423.0</td>\n",
       "      <td>11038.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-191.0</td>\n",
       "      <td>-88.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>-242.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>-336.0</td>\n",
       "      <td>-2380.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>782.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-76.0</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>-307.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>-376.0</td>\n",
       "      <td>-650.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-367.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>-215.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-1135.0</td>\n",
       "      <td>-962.0</td>\n",
       "      <td>-232.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>-501.0</td>\n",
       "      <td>16692.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-203.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-258.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>513.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>-204.0</td>\n",
       "      <td>-1772.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>1199.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>777.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>-41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-135.0</td>\n",
       "      <td>-114.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-419.0</td>\n",
       "      <td>-585.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>-253.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>-934.0</td>\n",
       "      <td>-577.0</td>\n",
       "      <td>-214.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>-107.0</td>\n",
       "      <td>-101.0</td>\n",
       "      <td>15763.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-357.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-131.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>-320.0</td>\n",
       "      <td>-2022.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>835.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>-110.0</td>\n",
       "      <td>627.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>-91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-106.0</td>\n",
       "      <td>-125.0</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>-230.0</td>\n",
       "      <td>-284.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-122.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>-471.0</td>\n",
       "      <td>-490.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-260.0</td>\n",
       "      <td>18128.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>-153.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-111.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 7129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Gene Accession Number  AFFX-BioB-5_at  AFFX-BioB-M_at  AFFX-BioB-3_at  \\\n",
       "1                              -214.0          -153.0           -58.0   \n",
       "2                              -139.0           -73.0            -1.0   \n",
       "3                               -76.0           -49.0          -307.0   \n",
       "4                              -135.0          -114.0           265.0   \n",
       "5                              -106.0          -125.0           -76.0   \n",
       "\n",
       "Gene Accession Number  AFFX-BioC-5_at  AFFX-BioC-3_at  AFFX-BioDn-5_at  \\\n",
       "1                                88.0          -295.0           -558.0   \n",
       "2                               283.0          -264.0           -400.0   \n",
       "3                               309.0          -376.0           -650.0   \n",
       "4                                12.0          -419.0           -585.0   \n",
       "5                               168.0          -230.0           -284.0   \n",
       "\n",
       "Gene Accession Number  AFFX-BioDn-3_at  AFFX-CreX-5_at  AFFX-CreX-3_at  \\\n",
       "1                                199.0          -176.0           252.0   \n",
       "2                               -330.0          -168.0           101.0   \n",
       "3                                 33.0          -367.0           206.0   \n",
       "4                                158.0          -253.0            49.0   \n",
       "5                                  4.0          -122.0            70.0   \n",
       "\n",
       "Gene Accession Number  AFFX-BioB-5_st  AFFX-BioB-M_st  AFFX-BioB-3_st  \\\n",
       "1                               206.0           -41.0          -831.0   \n",
       "2                                74.0            19.0          -743.0   \n",
       "3                              -215.0            19.0         -1135.0   \n",
       "4                                31.0           363.0          -934.0   \n",
       "5                               252.0           155.0          -471.0   \n",
       "\n",
       "Gene Accession Number  AFFX-BioC-5_st  AFFX-BioC-3_st  AFFX-BioDn-5_st  \\\n",
       "1                              -653.0          -462.0             75.0   \n",
       "2                              -239.0           -83.0            182.0   \n",
       "3                              -962.0          -232.0            208.0   \n",
       "4                              -577.0          -214.0            142.0   \n",
       "5                              -490.0          -184.0             32.0   \n",
       "\n",
       "Gene Accession Number  AFFX-BioDn-3_st  AFFX-CreX-5_st  AFFX-CreX-3_st  \\\n",
       "1                                381.0          -118.0          -565.0   \n",
       "2                                164.0          -141.0          -423.0   \n",
       "3                                432.0            84.0          -501.0   \n",
       "4                                271.0          -107.0          -101.0   \n",
       "5                                213.0             1.0          -260.0   \n",
       "\n",
       "Gene Accession Number  hum_alu_at  AFFX-DapX-5_at  AFFX-DapX-M_at  \\\n",
       "1                         15091.0             7.0           311.0   \n",
       "2                         11038.0            37.0           134.0   \n",
       "3                         16692.0           183.0           378.0   \n",
       "4                         15763.0            45.0           268.0   \n",
       "5                         18128.0           -28.0           118.0   \n",
       "\n",
       "Gene Accession Number  AFFX-DapX-3_at  AFFX-LysX-5_at  AFFX-LysX-M_at  \\\n",
       "1                              -231.0            21.0          -107.0   \n",
       "2                              -161.0           -21.0          -180.0   \n",
       "3                              -221.0            67.0          -203.0   \n",
       "4                               -27.0            43.0           -52.0   \n",
       "5                              -153.0            -8.0          -111.0   \n",
       "\n",
       "Gene Accession Number  AFFX-LysX-3_at  ...  Z34822_f_at  U87593_f_at  \\\n",
       "1                               165.0  ...       -325.0        -67.0   \n",
       "2                                18.0  ...       -191.0        -88.0   \n",
       "3                               238.0  ...       -258.0          9.0   \n",
       "4                               247.0  ...       -357.0         45.0   \n",
       "5                                44.0  ...        -78.0         29.0   \n",
       "\n",
       "Gene Accession Number  U88902_cds1_f_at  AC002076_cds2_at  D64015_at  \\\n",
       "1                                 346.0             -68.0      229.0   \n",
       "2                                 290.0              14.0      194.0   \n",
       "3                                 220.0             -58.0      294.0   \n",
       "4                                 430.0             -35.0      128.0   \n",
       "5                                 159.0              18.0       71.0   \n",
       "\n",
       "Gene Accession Number  HG2510-HT2606_at  L10717_at  L34355_at  L78833_cds4_at  \\\n",
       "1                                 -14.0      108.0       28.0           349.0   \n",
       "2                                  56.0      303.0     -242.0           214.0   \n",
       "3                                  95.0      143.0      -25.0           464.0   \n",
       "4                                  42.0       22.0     -131.0           342.0   \n",
       "5                                  42.0       44.0      -33.0           159.0   \n",
       "\n",
       "Gene Accession Number  M13981_at  M21064_at  M93143_at  S78825_at  U11863_at  \\\n",
       "1                           61.0      273.0      384.0     -306.0    -1827.0   \n",
       "2                          -28.0      143.0      231.0     -336.0    -2380.0   \n",
       "3                          513.0      238.0      720.0     -204.0    -1772.0   \n",
       "4                          142.0      277.0      307.0     -320.0    -2022.0   \n",
       "5                           71.0      134.0      178.0     -182.0     -179.0   \n",
       "\n",
       "Gene Accession Number  U29175_at  U48730_at  U58516_at  U73738_at  X06956_at  \\\n",
       "1                         1582.0      185.0      511.0     -125.0      389.0   \n",
       "2                          624.0      169.0      837.0      -36.0      442.0   \n",
       "3                          753.0      315.0     1199.0       33.0      168.0   \n",
       "4                          743.0      240.0      835.0      218.0      174.0   \n",
       "5                          626.0      156.0      649.0       57.0      504.0   \n",
       "\n",
       "Gene Accession Number  X16699_at  X83863_at  Z17240_at  L49218_f_at  \\\n",
       "1                          -37.0      793.0      329.0         36.0   \n",
       "2                          -17.0      782.0      295.0         11.0   \n",
       "3                           52.0     1138.0      777.0         41.0   \n",
       "4                         -110.0      627.0      170.0        -50.0   \n",
       "5                          -26.0      250.0      314.0         14.0   \n",
       "\n",
       "Gene Accession Number  M71243_f_at  Z78285_f_at  \n",
       "1                            191.0        -37.0  \n",
       "2                             76.0        -14.0  \n",
       "3                            228.0        -41.0  \n",
       "4                            126.0        -91.0  \n",
       "5                             56.0        -25.0  \n",
       "\n",
       "[5 rows x 7129 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the independent dataset into a pandas DataFrame from the 'data_set_ALL_AML_independent.csv' file\n",
    "data_indepen = pd.read_csv('data_set_ALL_AML_independent.csv', index_col=1)\n",
    "\n",
    "# Clean up independent dataset as done with the training dataset\n",
    "drop_list_2 = ['call'] + ['call.' + str(x) for x in range(1,34)]\n",
    "data_indepen = data_indepen.drop(columns=drop_list_2)\n",
    "data_indepen = data_indepen.drop(['Gene Description'], axis=1)\n",
    "data_indepen.columns = data_indepen.columns.astype(int)\n",
    "data_indepen.sort_index(axis=1, inplace=True)\n",
    "\n",
    "# Transpose the independent dataset so that rows are the different genes and columns are the patient samples\n",
    "gene_data_indepen = data_indepen.transpose()\n",
    "\n",
    "# Concatenate the gene expression data in the training and independent datasets into one dataframe\n",
    "gene_data = pd.concat([gene_data_train, gene_data_indepen], axis=0)\n",
    "gene_data = gene_data.astype(float)\n",
    "\n",
    "gene_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through earlier exploratory and statistical data analysis, I identified a subset of 50 genes to use as starting features for training machine learning models and created a file containing a variety of statisical information, including an estimate of correlation between each gene and the cancer type, for each of the 50 genes. I created a summary file containing summary statistics for each of the 7129 genes during previous analysis sorted by the calculated correlation value. I have imported this file and extracted the top 25 genes with the highest correlation for each cancer type; the first 25 rows have the largest negative correlation values and correspond to the genes most correlated with AML cancer, while the last 25 rows have the largest positive correlation values and correspond to the genes most correlated with ALL cancer. Using the new dataframe containing summary statistics for the top 50 genes, I created a list containing just the genes names. Finally, I then used this list to slice out the expression data for these genes from the dataframe containing all of the gene expression data to use as my feature data (X) for subsequent machine learning.\n",
    "\n",
    "I have also merged the gene expression dataframe with the file containing the labels for cancer type (ALL or AML) to create the labeled data, and then extracted the 'cancer' column to use as the labels (y) for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene</th>\n",
       "      <th>ALL_mean</th>\n",
       "      <th>AML_mean</th>\n",
       "      <th>ALL_stdev</th>\n",
       "      <th>AML_stdev</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>std_sum</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M55150_at</td>\n",
       "      <td>810.296296</td>\n",
       "      <td>1836.272727</td>\n",
       "      <td>338.178471</td>\n",
       "      <td>360.886434</td>\n",
       "      <td>-1025.976431</td>\n",
       "      <td>699.064905</td>\n",
       "      <td>-1.467641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U50136_rna1_at</td>\n",
       "      <td>977.777778</td>\n",
       "      <td>2562.181818</td>\n",
       "      <td>324.689003</td>\n",
       "      <td>789.747785</td>\n",
       "      <td>-1584.404040</td>\n",
       "      <td>1114.436788</td>\n",
       "      <td>-1.421708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X95735_at</td>\n",
       "      <td>349.888889</td>\n",
       "      <td>3023.636364</td>\n",
       "      <td>395.515567</td>\n",
       "      <td>1506.464687</td>\n",
       "      <td>-2673.747475</td>\n",
       "      <td>1901.980255</td>\n",
       "      <td>-1.405770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M16038_at</td>\n",
       "      <td>375.370370</td>\n",
       "      <td>1811.636364</td>\n",
       "      <td>240.297436</td>\n",
       "      <td>953.688238</td>\n",
       "      <td>-1436.265993</td>\n",
       "      <td>1193.985673</td>\n",
       "      <td>-1.202917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M23197_at</td>\n",
       "      <td>175.037037</td>\n",
       "      <td>767.272727</td>\n",
       "      <td>84.092660</td>\n",
       "      <td>411.098307</td>\n",
       "      <td>-592.235690</td>\n",
       "      <td>495.190967</td>\n",
       "      <td>-1.195974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Gene    ALL_mean     AML_mean   ALL_stdev    AML_stdev  \\\n",
       "0       M55150_at  810.296296  1836.272727  338.178471   360.886434   \n",
       "1  U50136_rna1_at  977.777778  2562.181818  324.689003   789.747785   \n",
       "2       X95735_at  349.888889  3023.636364  395.515567  1506.464687   \n",
       "3       M16038_at  375.370370  1811.636364  240.297436   953.688238   \n",
       "4       M23197_at  175.037037   767.272727   84.092660   411.098307   \n",
       "\n",
       "     mean_diff      std_sum  correlation  \n",
       "0 -1025.976431   699.064905    -1.467641  \n",
       "1 -1584.404040  1114.436788    -1.421708  \n",
       "2 -2673.747475  1901.980255    -1.405770  \n",
       "3 -1436.265993  1193.985673    -1.202917  \n",
       "4  -592.235690   495.190967    -1.195974  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in 'gene_summary.csv' file created earlier, which contains gene correlation values\n",
    "gene_summary = pd.read_csv('gene_summary.csv')\n",
    "gene_summary.rename({\"Unnamed: 0\": \"Gene\"}, axis=1, inplace=True)\n",
    "gene_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Gene Accession Number</th>\n",
       "      <th>M55150_at</th>\n",
       "      <th>U50136_rna1_at</th>\n",
       "      <th>X95735_at</th>\n",
       "      <th>M16038_at</th>\n",
       "      <th>M23197_at</th>\n",
       "      <th>M84526_at</th>\n",
       "      <th>Y12670_at</th>\n",
       "      <th>U82759_at</th>\n",
       "      <th>D49950_at</th>\n",
       "      <th>M27891_at</th>\n",
       "      <th>X17042_at</th>\n",
       "      <th>U12471_cds1_at</th>\n",
       "      <th>U46751_at</th>\n",
       "      <th>Y00787_s_at</th>\n",
       "      <th>L08246_at</th>\n",
       "      <th>M80254_at</th>\n",
       "      <th>M62762_at</th>\n",
       "      <th>M81933_at</th>\n",
       "      <th>M96326_rna1_at</th>\n",
       "      <th>M28130_rna1_s_at</th>\n",
       "      <th>M63138_at</th>\n",
       "      <th>M11147_at</th>\n",
       "      <th>M57710_at</th>\n",
       "      <th>M81695_s_at</th>\n",
       "      <th>X85116_rna1_s_at</th>\n",
       "      <th>J05243_at</th>\n",
       "      <th>Z69881_at</th>\n",
       "      <th>U20998_at</th>\n",
       "      <th>X63469_at</th>\n",
       "      <th>D38073_at</th>\n",
       "      <th>U29175_at</th>\n",
       "      <th>M91432_at</th>\n",
       "      <th>S50223_at</th>\n",
       "      <th>AF009426_at</th>\n",
       "      <th>X15949_at</th>\n",
       "      <th>X52142_at</th>\n",
       "      <th>Z15115_at</th>\n",
       "      <th>M28170_at</th>\n",
       "      <th>L47738_at</th>\n",
       "      <th>U32944_at</th>\n",
       "      <th>M31523_at</th>\n",
       "      <th>D26156_s_at</th>\n",
       "      <th>U09087_s_at</th>\n",
       "      <th>M31211_s_at</th>\n",
       "      <th>L13278_at</th>\n",
       "      <th>X74262_at</th>\n",
       "      <th>M92287_at</th>\n",
       "      <th>U05259_rna1_at</th>\n",
       "      <th>X59417_at</th>\n",
       "      <th>U22376_cds2_s_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>654.0</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>-283.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1298.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>-88.0</td>\n",
       "      <td>835.0</td>\n",
       "      <td>-240.0</td>\n",
       "      <td>782.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>5418.0</td>\n",
       "      <td>-115.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>610.0</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>1753.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>994.0</td>\n",
       "      <td>1582.0</td>\n",
       "      <td>767.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>8444.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>3349.0</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>1595.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1372.0</td>\n",
       "      <td>4778.0</td>\n",
       "      <td>9326.0</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>3105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1283.0</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1358.0</td>\n",
       "      <td>3460.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1379.0</td>\n",
       "      <td>5345.0</td>\n",
       "      <td>2972.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>3072.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>2062.0</td>\n",
       "      <td>2325.0</td>\n",
       "      <td>17348.0</td>\n",
       "      <td>2171.0</td>\n",
       "      <td>812.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1602.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>539.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>814.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>-114.0</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>2893.0</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>822.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1184.0</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>895.0</td>\n",
       "      <td>3424.0</td>\n",
       "      <td>1118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1286.0</td>\n",
       "      <td>1398.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>-395.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>1496.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>2789.0</td>\n",
       "      <td>6156.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>1697.0</td>\n",
       "      <td>3556.0</td>\n",
       "      <td>2761.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>1441.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>1547.0</td>\n",
       "      <td>804.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>3118.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>2723.0</td>\n",
       "      <td>2089.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>1452.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>2221.0</td>\n",
       "      <td>4926.0</td>\n",
       "      <td>628.0</td>\n",
       "      <td>7724.0</td>\n",
       "      <td>4543.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>915.0</td>\n",
       "      <td>942.0</td>\n",
       "      <td>693.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>-367.0</td>\n",
       "      <td>716.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>-304.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1401.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>-111.0</td>\n",
       "      <td>935.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1132.0</td>\n",
       "      <td>7070.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>828.0</td>\n",
       "      <td>1486.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>831.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>4261.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>1644.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1051.0</td>\n",
       "      <td>5403.0</td>\n",
       "      <td>5314.0</td>\n",
       "      <td>3821.0</td>\n",
       "      <td>5467.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>732.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>713.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>524.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>7972.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1894.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>2453.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>1269.0</td>\n",
       "      <td>9017.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>1496.0</td>\n",
       "      <td>2298.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>1423.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>3425.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>3502.0</td>\n",
       "      <td>1322.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>661.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>1370.0</td>\n",
       "      <td>3440.0</td>\n",
       "      <td>5354.0</td>\n",
       "      <td>5216.0</td>\n",
       "      <td>3469.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Gene Accession Number  M55150_at  U50136_rna1_at  X95735_at  M16038_at  \\\n",
       "1                          654.0          1124.0      298.0      365.0   \n",
       "2                         1283.0          1062.0      307.0      624.0   \n",
       "3                         1286.0          1398.0      309.0      108.0   \n",
       "4                          915.0           942.0      693.0      873.0   \n",
       "5                          732.0           928.0      713.0      686.0   \n",
       "\n",
       "Gene Accession Number  M23197_at  M84526_at  Y12670_at  U82759_at  D49950_at  \\\n",
       "1                          261.0     -283.0      600.0      393.0       75.0   \n",
       "2                          101.0      -65.0      337.0      118.0      129.0   \n",
       "3                          309.0     -395.0      574.0      667.0       44.0   \n",
       "4                          288.0     -367.0      716.0      410.0      218.0   \n",
       "5                          395.0      290.0      524.0      119.0      110.0   \n",
       "\n",
       "Gene Accession Number  M27891_at  X17042_at  U12471_cds1_at  U46751_at  \\\n",
       "1                          303.0      177.0           160.0     1298.0   \n",
       "2                         1358.0     3460.0           134.0     1379.0   \n",
       "3                          254.0      416.0           167.0     1496.0   \n",
       "4                         -304.0      392.0           104.0     1401.0   \n",
       "5                          -86.0     7972.0           145.0     1894.0   \n",
       "\n",
       "Gene Accession Number  Y00787_s_at  L08246_at  M80254_at  M62762_at  \\\n",
       "1                            333.0      543.0      -88.0      835.0   \n",
       "2                           5345.0     2972.0      109.0     3072.0   \n",
       "3                            301.0      485.0      -53.0      609.0   \n",
       "4                            241.0      740.0     -111.0      935.0   \n",
       "5                             93.0     2453.0      139.0     1665.0   \n",
       "\n",
       "Gene Accession Number  M81933_at  M96326_rna1_at  M28130_rna1_s_at  M63138_at  \\\n",
       "1                         -240.0           782.0             292.0     1410.0   \n",
       "2                          -11.0           368.0            2062.0     2325.0   \n",
       "3                          124.0          1268.0             -25.0     2789.0   \n",
       "4                          167.0           882.0              -2.0     1132.0   \n",
       "5                          114.0           949.0             138.0     1269.0   \n",
       "\n",
       "Gene Accession Number  M11147_at  M57710_at  M81695_s_at  X85116_rna1_s_at  \\\n",
       "1                         5418.0     -115.0        695.0             162.0   \n",
       "2                        17348.0     2171.0        812.0             169.0   \n",
       "3                         6156.0      -26.0        810.0             -18.0   \n",
       "4                         7070.0       22.0        599.0             199.0   \n",
       "5                         9017.0      244.0        282.0             334.0   \n",
       "\n",
       "Gene Accession Number  J05243_at  Z69881_at  U20998_at  X63469_at  D38073_at  \\\n",
       "1                          610.0     1766.0     1753.0      460.0      994.0   \n",
       "2                          927.0     2015.0     1602.0      151.0      539.0   \n",
       "3                         1697.0     3556.0     2761.0      230.0     1441.0   \n",
       "4                          425.0      828.0     1486.0      314.0      680.0   \n",
       "5                          529.0     1496.0     2298.0      632.0      950.0   \n",
       "\n",
       "Gene Accession Number  U29175_at  M91432_at  S50223_at  AF009426_at  \\\n",
       "1                         1582.0      767.0      268.0         36.0   \n",
       "2                          624.0      814.0      346.0         58.0   \n",
       "3                          753.0     1547.0      804.0         63.0   \n",
       "4                          743.0      831.0      452.0         38.0   \n",
       "5                          626.0     1423.0      476.0        120.0   \n",
       "\n",
       "Gene Accession Number  X15949_at  X52142_at  Z15115_at  M28170_at  L47738_at  \\\n",
       "1                          277.0      107.0     8444.0      397.0      571.0   \n",
       "2                          104.0     -114.0     1920.0      -39.0     2893.0   \n",
       "3                           91.0      -13.0     3118.0      183.0     2723.0   \n",
       "4                          403.0      190.0     4261.0      363.0      731.0   \n",
       "5                          416.0      361.0     3425.0      251.0      649.0   \n",
       "\n",
       "Gene Accession Number  U32944_at  M31523_at  D26156_s_at  U09087_s_at  \\\n",
       "1                         3349.0     1320.0       1595.0        358.0   \n",
       "2                         1002.0      898.0        822.0         82.0   \n",
       "3                         2089.0      597.0       1452.0        263.0   \n",
       "4                         1625.0     1644.0        654.0        218.0   \n",
       "5                         3502.0     1322.0       1011.0        186.0   \n",
       "\n",
       "Gene Accession Number  M31211_s_at  L13278_at  X74262_at  M92287_at  \\\n",
       "1                            601.0      193.0     1372.0     4778.0   \n",
       "2                            435.0       31.0     1184.0     2700.0   \n",
       "3                            547.0      198.0     2221.0     4926.0   \n",
       "4                            472.0       91.0     1051.0     5403.0   \n",
       "5                            661.0      194.0     1370.0     3440.0   \n",
       "\n",
       "Gene Accession Number  U05259_rna1_at  X59417_at  U22376_cds2_s_at  \n",
       "1                              9326.0     3016.0            3105.0  \n",
       "2                               895.0     3424.0            1118.0  \n",
       "3                               628.0     7724.0            4543.0  \n",
       "4                              5314.0     3821.0            5467.0  \n",
       "5                              5354.0     5216.0            3469.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slice out top 25 genes with highest (+) correlation values and highest (-) correlation values\n",
    "top_50_gene_summary = pd.concat([gene_summary.iloc[0:25, :], gene_summary.iloc[-25:, :]], axis=0).reset_index(drop=True)\n",
    "# Create a list with the names of the top 50 genes\n",
    "top_50_gene_names = list(top_50_gene_summary['Gene'])\n",
    "# Slice out expression data for top 50 genes to use as X data for training classifiers\n",
    "X = gene_data.loc[:, top_50_gene_names]\n",
    "\n",
    "# Merge the key dataframe containing the cancer labels with the gene_data dataframe to assign the cancer type to each patient sample\n",
    "labeled_data = pd.concat([key, gene_data], axis=1, join='inner')\n",
    "\n",
    "# Pull out just the labels from the labelled data to use for training classifiers\n",
    "y = labeled_data.cancer\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature data and labels are now readily available as X and y and can be used to assess different machine learning algorithms. As a first step, I have decided to analyze the performance of a k-Nearest Neighbors classifier. Before jumping into hyperparameter tuning and cross-validation, however, I have first split my dataset into training and test sets. The training data, X_train and y_train, were used for hyperparameter tuning and cross-validation, while the test sets, X_test and y_test, were reserved for the final performance assesment of the optimized kNN classifier.\n",
    "As the gene expression data can vary widely from gene to gene, the data must also be preprocessed before training classifiers to standardize the variance. Therefore, I have also used transformers to standardize or normalize the gene expression data in subsequent analyses.\n",
    "\n",
    "The kNN classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_neighbors is 11\n",
      "\n",
      "Accuracy: 95.45%\n",
      "\n",
      "Confusion matrix: \n",
      "[[14  0]\n",
      " [ 1  7]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ALL       0.93      1.00      0.97        14\n",
      "         AML       1.00      0.88      0.93         8\n",
      "\n",
      "   micro avg       0.95      0.95      0.95        22\n",
      "   macro avg       0.97      0.94      0.95        22\n",
      "weighted avg       0.96      0.95      0.95        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier, NearestCentroid, KDTree\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Split data into train and test sets; stratify split so that AML samples have the same proportion in both train & test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42, stratify=y)\n",
    "\n",
    "# Initiate normalizer, kNN Classifier, and pipeline\n",
    "knn_pipeline = Pipeline(steps=[('normalizer', Normalizer()), ('knn', KNeighborsClassifier())])\n",
    "\n",
    "# Set list of parameters to test\n",
    "parameters = {'knn__n_neighbors': np.arange(1, 20)}\n",
    "\n",
    "# Perform GridSearch on list of parameters, then fit the model\n",
    "knn_cv = GridSearchCV(knn_pipeline, param_grid=parameters, cv=5, iid=False)\n",
    "knn_cv.fit(X_train, y_train)\n",
    "y_pred = knn_cv.predict(X_test)\n",
    "\n",
    "# Print out classification metrics\n",
    "print('Best n_neighbors is {}\\n'.format(knn_cv.best_params_['knn__n_neighbors']))\n",
    "print('Accuracy: {:.2%}\\n'.format(knn_cv.score(X_test, y_test)))\n",
    "print('Confusion matrix: \\n{}\\n'.format(confusion_matrix(y_test, y_pred)))\n",
    "print('Classification report: \\n{}'.format(classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next section, I have assessed the performance of a logistic regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.45%\n",
      "\n",
      "Confusion matrix: \n",
      "[[14  0]\n",
      " [ 1  7]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ALL       0.93      1.00      0.97        14\n",
      "         AML       1.00      0.88      0.93         8\n",
      "\n",
      "   micro avg       0.95      0.95      0.95        22\n",
      "   macro avg       0.97      0.94      0.95        22\n",
      "weighted avg       0.96      0.95      0.95        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "logreg_pipeline = Pipeline(steps=[('normalizer', Normalizer()),('logreg', LogisticRegression(solver='lbfgs'))])\n",
    "#X_train_norm = normalize(X_train)\n",
    "#logreg = LogisticRegression(solver='lbfgs')\n",
    "#logreg.fit(X_train_norm, y_train)\n",
    "\n",
    "\n",
    "logreg_pipeline.fit(X_train, y_train)\n",
    "logreg_y_pred = logreg_pipeline.predict(X_test)\n",
    "y_pred_prob = logreg_pipeline.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob, pos_label='AML')\n",
    "\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "# Print classification metrics\n",
    "print('Accuracy: {:.2%}\\n'.format(logreg_pipeline.score(X_test, y_test)))\n",
    "print('Confusion matrix: \\n{}\\n'.format(confusion_matrix(y_test, logreg_y_pred)))\n",
    "print('Classification report: \\n{}'.format(classification_report(y_test, logreg_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C is 0.75\n",
      "Best gamma is 2\n",
      "\n",
      "Accuracy: 95.45%\n",
      "\n",
      "Confusion matrix: \n",
      "[[14  0]\n",
      " [ 1  7]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ALL       0.93      1.00      0.97        14\n",
      "         AML       1.00      0.88      0.93         8\n",
      "\n",
      "   micro avg       0.95      0.95      0.95        22\n",
      "   macro avg       0.97      0.94      0.95        22\n",
      "weighted avg       0.96      0.95      0.95        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initiate SVC pipeline\n",
    "svc_pipeline = Pipeline(steps=[('normalizer', Normalizer()),('svc', SVC())])\n",
    "\n",
    "# Set parameters to test\n",
    "parameters = {'svc__C': [0.01, 0.1, 0.5, 0.75, 1, 1.25, 1.5, 2], 'svc__gamma': [0.01, 0.1, 0.5, 0.75, 1, 1.25, 1.5, 2, 2.5]}\n",
    "\n",
    "# Perform GridSearch on list of parameters, then fit the model\n",
    "svc_cv = GridSearchCV(svc_pipeline, param_grid=parameters, cv=5, iid=False)\n",
    "svc_cv.fit(X_train, y_train)\n",
    "svc_y_pred = svc_cv.predict(X_test)\n",
    "\n",
    "# Print out classification metrics\n",
    "print('Best C is {}'.format(svc_cv.best_params_['svc__C']))\n",
    "print('Best gamma is {}\\n'.format(svc_cv.best_params_['svc__gamma']))\n",
    "print('Accuracy: {:.2%}\\n'.format(svc_cv.score(X_test, y_test)))\n",
    "print('Confusion matrix: \\n{}\\n'.format(confusion_matrix(y_test, svc_y_pred)))\n",
    "print('Classification report: \\n{}'.format(classification_report(y_test, svc_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_estimators is: 500\n",
      "\n",
      "Accuracy: 95.45%\n",
      "\n",
      "Confusion matrix: \n",
      "[[14  0]\n",
      " [ 1  7]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ALL       0.93      1.00      0.97        14\n",
      "         AML       1.00      0.88      0.93         8\n",
      "\n",
      "   micro avg       0.95      0.95      0.95        22\n",
      "   macro avg       0.97      0.94      0.95        22\n",
      "weighted avg       0.96      0.95      0.95        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Initiate RandomForest pipeline\n",
    "rfc_pipeline = Pipeline(steps=[('normalizer', Normalizer()),('rfc', RandomForestClassifier())])\n",
    "\n",
    "# Set parameters to test\n",
    "parameters = {'rfc__n_estimators': [10, 25, 50, 75, 100, 500]}\n",
    "\n",
    "# Perform GridSearch on list of parameters, then fit the model\n",
    "rfc_cv = GridSearchCV(rfc_pipeline, param_grid=parameters, cv=5, iid=False)\n",
    "\n",
    "# Fit and predict classifier\n",
    "rfc_cv.fit(X_train, y_train)\n",
    "rfc_y_pred = rfc_cv.predict(X_test)\n",
    "\n",
    "# Print out classification metrics\n",
    "print('Best n_estimators is: {}\\n'.format(rfc_cv.best_params_['rfc__n_estimators']))\n",
    "print('Accuracy: {:.2%}\\n'.format(rfc_cv.score(X_test, y_test)))\n",
    "print('Confusion matrix: \\n{}\\n'.format(confusion_matrix(y_test, rfc_y_pred)))\n",
    "print('Classification report: \\n{}'.format(classification_report(y_test, rfc_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
